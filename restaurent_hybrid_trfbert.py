# -*- coding: utf-8 -*-
"""restaurent_hybrid_trfbert.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rd-efQKnSbkcEiuentH6CFyrWPzMe7SG

xbert
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install transformers

!pip install sentencepiece

"""Hybrid-pol-final"""

import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from transformers import BertTokenizer, TFBertForSequenceClassification
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.layers import Input, Dense, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# Load your Excel dataset
data = pd.read_excel("/content/drive/MyDrive/SA/Restaurant.xlsx")

# Split data into categories, sentiments, and opinions
categories = data['Polarity'].astype(str)

# Tokenize and preprocess the category data based on correct aspects
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

category_sequences = tokenizer(list(categories), truncation=True, padding=True, return_tensors='tf', max_length=64)

# Convert category labels to categorical format
label_encoder_category = LabelEncoder()
y_category_encoded = label_encoder_category.fit_transform(categories)

# Convert TensorFlow tensors to NumPy arrays
X_category = np.array(category_sequences['input_ids'])
y_category = y_category_encoded

# Use a random train-test split
X_train_category, X_test_category, y_train_category, y_test_category = train_test_split(
    X_category, y_category, test_size=0.2, random_state=42)

# Load the pre-trained BERT model for category classification
num_category_classes = len(label_encoder_category.classes_)
model_category = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_category_classes)

# Create a custom optimizer with a lower learning rate
optimizer_custom = tf.keras.optimizers.Adam(learning_rate=1e-5)

# Compile the model with custom optimizer and evaluation metric
model_category.compile(optimizer=optimizer_custom, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Define early stopping and learning rate reduction callbacks
early_stopping_category = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
reduce_lr_category = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-7)

# Fine-tune the category classification model with dropout layers
history = model_category.fit(
    X_train_category, y_train_category, epochs=10, batch_size=32,
    validation_split=0.2, callbacks=[early_stopping_category, reduce_lr_category])

# Use the trained category classification model to predict categories
predicted_categories = model_category.predict(X_test_category)
predicted_categories_classes = np.argmax(predicted_categories[0], axis=1)

# Calculate accuracy for category classification
accuracy_category = accuracy_score(y_test_category, predicted_categories_classes)
print("Accuracy for Category Classification:", accuracy_category)

# Vectorize the text data for Random Forest
vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
X_train_rf = vectorizer.fit_transform(categories[:len(X_train_category)])
X_test_rf = vectorizer.transform(categories[len(X_train_category):])

# Encode the test category labels for Random Forest evaluation
y_test_category_encoded = label_encoder_category.transform(categories[len(X_train_category):])

# Create the Random Forest classifier with dropout
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the Random Forest classifier
rf_model.fit(X_train_rf, y_train_category)

# Use the trained Random Forest model to predict
X_test_rf_predictions = rf_model.predict(X_test_rf)

# Ensure the data types match for concatenation
X_test_rf_predictions = X_test_rf_predictions.astype(np.float32)

# Combine BERT features with machine learning predictions
combined_features = np.concatenate([predicted_categories[0], X_test_rf_predictions.reshape(-1, 1)], axis=1)

# Build the final hybrid model for category classification with dropout in BERT
input_layer = Input(shape=(num_category_classes + 1))
dropout_layer = Dropout(0.2)(input_layer)  # Add dropout
dense_layer = Dense(128, activation='relu')(dropout_layer)
output_layer = Dense(num_category_classes, activation='softmax')(dense_layer)
model_hybrid = Model(inputs=input_layer, outputs=output_layer)

# Compile the hybrid model
model_hybrid.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train the hybrid model with dropout in BERT
model_hybrid.fit(combined_features, y_test_category, epochs=10, batch_size=32, validation_split=0.2)

# Evaluate the hybrid model on the test set
test_loss, test_accuracy = model_hybrid.evaluate(combined_features, y_test_category)
print("Test Loss:", test_loss)
print("Test Accuracy:", test_accuracy)

from sklearn.metrics import classification_report

# Make predictions using the hybrid model
y_pred_hybrid = model_hybrid.predict(combined_features)
y_pred_hybrid_classes = np.argmax(y_pred_hybrid, axis=1)

# Generate the classification report
classification_report_hybrid = classification_report(y_test_category, y_pred_hybrid_classes)

# Print the classification report
print("Classification Report for the Hybrid Model:\n", classification_report_hybrid)

"""hybrid-polarity"""

import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from transformers import BertTokenizer, TFBertForSequenceClassification
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.layers import Input, Dense, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# Load your Excel dataset
data = pd.read_excel("/content/drive/MyDrive/SA/Restaurant.xlsx")

# Split data into categories, sentiments, and opinions
categories = data['Polarity'].astype(str)

# Tokenize and preprocess the category data based on correct aspects
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

category_sequences = tokenizer(list(categories), truncation=True, padding=True, return_tensors='tf', max_length=64)

# Convert category labels to categorical format
label_encoder_category = LabelEncoder()
y_category_encoded = label_encoder_category.fit_transform(categories)

# Convert TensorFlow tensors to NumPy arrays
X_category = np.array(category_sequences['input_ids'])
y_category = y_category_encoded

# Use a random train-test split
X_train_category, X_test_category, y_train_category, y_test_category = train_test_split(
    X_category, y_category, test_size=0.2, random_state=42)

# Load the pre-trained BERT model for category classification
num_category_classes = len(label_encoder_category.classes_)
model_category = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_category_classes)

# Create a custom optimizer with a lower learning rate
optimizer_custom = tf.keras.optimizers.Adam(learning_rate=1e-5)

# Compile the model with custom optimizer and evaluation metric
model_category.compile(optimizer=optimizer_custom, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Define early stopping and learning rate reduction callbacks
early_stopping_category = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
reduce_lr_category = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-7)

# Fine-tune the category classification model with dropout layers
history = model_category.fit(
    X_train_category, y_train_category, epochs=10, batch_size=32,
    validation_split=0.2, callbacks=[early_stopping_category, reduce_lr_category])

# Use the trained category classification model to predict categories
predicted_categories = model_category.predict(X_test_category)
predicted_categories_classes = np.argmax(predicted_categories[0], axis=1)

# Calculate accuracy for category classification
accuracy_category = accuracy_score(y_test_category, predicted_categories_classes)
print("Accuracy for Category Classification:", accuracy_category)

# Vectorize the text data for Random Forest
vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
X_train_rf = vectorizer.fit_transform(categories[:len(X_train_category)])
X_test_rf = vectorizer.transform(categories[len(X_train_category):])

# Encode the test category labels for Random Forest evaluation
y_test_category_encoded = label_encoder_category.transform(categories[len(X_train_category):])

# Create the Random Forest classifier with dropout
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the Random Forest classifier
rf_model.fit(X_train_rf, y_train_category)

# Use the trained Random Forest model to predict
X_test_rf_predictions = rf_model.predict(X_test_rf)

# Ensure the data types match for concatenation
X_test_rf_predictions = X_test_rf_predictions.astype(np.float32)

# Combine BERT features with machine learning predictions
combined_features = np.concatenate([predicted_categories[0], X_test_rf_predictions.reshape(-1, 1)], axis=1)

# Build the final hybrid model for category classification with dropout in BERT
input_layer = Input(shape=(num_category_classes + 1))
dropout_layer = Dropout(0.2)(input_layer)  # Add dropout
dense_layer = Dense(128, activation='relu')(dropout_layer)
output_layer = Dense(num_category_classes, activation='softmax')(dense_layer)
model_hybrid = Model(inputs=input_layer, outputs=output_layer)

# Compile the hybrid model
model_hybrid.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train the hybrid model with dropout in BERT
model_hybrid.fit(combined_features, y_test_category, epochs=10, batch_size=32, validation_split=0.2)

# Evaluate the hybrid model on the test set
test_loss, test_accuracy = model_hybrid.evaluate(combined_features, y_test_category)
print("Test Loss:", test_loss)
print("Test Accuracy:", test_accuracy)

from sklearn.metrics import classification_report

# Make predictions using the hybrid model
y_pred_hybrid = model_hybrid.predict(combined_features)
y_pred_hybrid_classes = np.argmax(y_pred_hybrid, axis=1)

# Generate the classification report
classification_report_hybrid = classification_report(y_test_category, y_pred_hybrid_classes)

# Print the classification report
print("Classification Report for the Hybrid Model:\n", classification_report_hybrid)